{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "\n",
    "Pooling consiste em reduzir o tamanho de uma imagem. Isso é importante por diversos motivos:\n",
    "\n",
    "1. Podemos reduzir o custo computacional de processar imagens muito grandes\n",
    "2. Permite capturar características de uma imagem em múltiplas escalas\n",
    "3. Em tarefas de classificação, queremos que a saída da rede seja um único valor. Isso em geral é feito reduzindo aos poucos o tamanho da imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operações de pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.,  7.],\n",
      "          [ 8.,  9., 10., 11.],\n",
      "          [12., 13., 14., 15.]]]])\n",
      "tensor([[[[ 5.,  6.,  7.],\n",
      "          [ 9., 10., 11.],\n",
      "          [13., 14., 15.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Batch de uma imagem de tamanho 4x4 possuindo 1 canal\n",
    "x = torch.arange(0, 16,).float().reshape(1,1,4,4)\n",
    "y = F.max_pool2d(x, kernel_size=2, stride=1)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.,  7.],\n",
      "          [ 8.,  9., 10., 11.],\n",
      "          [12., 13., 14., 15.]]]])\n",
      "tensor([[[[ 5.,  7.],\n",
      "          [13., 15.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Por padrão, a função max_pool2d utiliza stride=kernel_size, o que efetivamente reduz\n",
    "# o tamanho da imagem pela metade\n",
    "y = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.,  7.],\n",
      "          [ 8.,  9., 10., 11.],\n",
      "          [12., 13., 14., 15.]]]])\n",
      "tensor([[[[ 2.5000,  4.5000],\n",
      "          [10.5000, 12.5000]]]])\n"
     ]
    }
   ],
   "source": [
    "# Outra operação de pooling é o average pooling\n",
    "y = F.avg_pool2d(x, kernel_size=2)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5000,  4.5000],\n",
      "          [10.5000, 12.5000]]]])\n"
     ]
    }
   ],
   "source": [
    "# A operação acima é equivalente a convoluir a imagem com o seguinte filtro de média:\n",
    "w = torch.tensor([[1,1],[1,1]])/4\n",
    "w = w.reshape(1,1,2,2)\n",
    "\n",
    "y = F.conv2d(x, w, stride=2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling adaptativo\n",
    "\n",
    "Toda rede de classificação precisa que a saída tenha um tamanho padrão e fixo. Camadas de pooling adaptativo possibilitam fixar o tamanho da saída. O stride, tamanho e padding do kernel é ajustado automaticamente para que a saída tenha o tamanho desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.5000,  3.5000,  4.5000],\n",
       "          [ 6.5000,  7.5000,  8.5000],\n",
       "          [10.5000, 11.5000, 12.5000]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixa a saída em tamanho 3x3\n",
    "F.adaptive_avg_pool2d(x, output_size=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camadas de pooling\n",
    "\n",
    "As funções que utilizamos acima estão implementadas como camadas do Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 112, 112]) torch.Size([1, 3, 56, 56]) torch.Size([1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "pool3 = nn.AdaptiveAvgPool2d(output_size=(5,5))\n",
    "\n",
    "x = torch.rand((1,3,224,224))\n",
    "y1 = pool1(x)\n",
    "y2 = pool2(y1)\n",
    "y3 = pool3(y2)\n",
    "\n",
    "print(y1.shape, y2.shape, y3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante notar que essas camadas de pooling **não possuem parâmetros treináveis**, isto é, não é possível otimizar parâmetros dessas camadas durante o treinamento. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
