{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceitos de Paralelismo e treinamento em múltiplas GPUs [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/chcomin/curso-visao-computacional-2024/blob/main/M12_topicos_extra/2%20-%20Paralelismo%20\\(GPU\\).ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralelismo no pré-processamento de dados\n",
    "\n",
    "O dataloader do Pytorch possibilita paralelizar de forma fácil o pré-processamento de dados. O arquivo dataloader.py possui um exemplo de um dataset com 15 itens, batch size de tamanho 4 e 3 `workers`, que são processos paralelos criados pelo dataloader. O dataset retorna o índice do processo responsável por ler cada item do dataset.\n",
    "\n",
    "Nota: precisamos criar o arquivo dataloader.py porque o dataloader cria novos processos do interpretador Python, o que não pode ser feito em código interativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx=0\n",
      "['idx=0 processado por worker 0', 'idx=1 processado por worker 0', 'idx=2 processado por worker 0', 'idx=3 processado por worker 0']\n",
      "batch_idx=1\n",
      "['idx=4 processado por worker 1', 'idx=5 processado por worker 1', 'idx=6 processado por worker 1', 'idx=7 processado por worker 1']\n",
      "batch_idx=2\n",
      "['idx=8 processado por worker 2', 'idx=9 processado por worker 2', 'idx=10 processado por worker 2', 'idx=11 processado por worker 2']\n",
      "batch_idx=3\n",
      "['idx=12 processado por worker 0', 'idx=13 processado por worker 0', 'idx=14 processado por worker 0']\n"
     ]
    }
   ],
   "source": [
    "import dataloader\n",
    "\n",
    "dataloader.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando com múltiplas GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "device1 = 'cuda:0'\n",
    "# Vamos usar a cpu como se fosse outra gpu. Normalmente usaríamos 'cuda:1'\n",
    "device2 = 'cpu' \n",
    "# Lista de dispositivos disponíveis. Poderiam ser n GPUs!\n",
    "devices = [device1, device2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execução de partes do cálculo em diferentes dispositivos\n",
    "\n",
    "O Pytorch permite trocar a qualquer momento de dispositivo. **O cálculo do gradiente é propagado entre os dispotitivos**. Mas é preciso tomar cuidado que cópias entre dispositivos são custosas e requerem sincronização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 6., 6.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.tensor([1., 2., 3.], requires_grad=True, device=device1)\n",
    "x1 = 2*x0.to(device2)        # Envia tensor para device2\n",
    "x2 = (3*x1 + 5).to(device1)  # Envia tensor para device1\n",
    "x3 = x2.sum().to(device2)    # Envia tensor para device2\n",
    "x3.backward()\n",
    "# Valor esperado: grad=2*3\n",
    "print(x0.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, podemos colocar cada parte do modelo em uma GPU distinta, e calcular os gradientes normalmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    '''Uma rede básica só para exemplificar.'''\n",
    "    \n",
    "    def __init__(self, device1, device2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device1 = device1\n",
    "        self.device2 = device2\n",
    "\n",
    "        # Camadas estão no device1\n",
    "        self.layers1 = nn.Sequential(\n",
    "            nn.Conv2d(1,1,1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU()\n",
    "        ).to(device1)\n",
    "\n",
    "        # Camadas estão no device2\n",
    "        self.layers2 = nn.Sequential(\n",
    "            nn.Conv2d(1,1,1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU()\n",
    "        ).to(device2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.to(self.device1)\n",
    "        # Aplica camada e envia para o device2\n",
    "        x = self.layers1(x).to(self.device2)\n",
    "        x = self.layers2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = Model(device1, device2)\n",
    "x = torch.rand(1, 1, 224, 224, device=device1)\n",
    "out = model(x)\n",
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo acima é útil quando um modelo não cabe em uma única GPU. Os parâmetros, ativações e gradientes de cada camada são salvas na GPU que a camada está alocada. Todo o resto do treinamento da rede é exatamente igual ao caso que a rede está em uma única GPU, pois o otimizador irá atualizar os parâmetros corretamente em cada dispositivo. \n",
    "\n",
    "A desvantagem dessa implementação é que uma GPU fica ociosa enquanto a outra está executando. É possível otimizar esse exemplo para manter ambas as GPUs ocupadas, mas a lógica fica um pouco mais complicada. Esse processo é chamado de *pipeline parallelism*. Veja um exemplo em https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html#speed-up-by-pipelining-inputs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paralelismo de dados\n",
    "\n",
    "O paralelismo de dados consiste em dividir um batch entre os dispositivos. Por exemplo, em um sistema com 4 GPUs, um batch de tamanho 64 é dividido em minibatches de tamanho 16, e cada minibatch é enviado para uma GPU. Os dados divididos são chamados de *shards*.\n",
    "\n",
    "Inicialmente, a rede é copiada para cada GPU. No treinamento, cada modelo processa o minibatch de forma independente, e os gradientes são calculados também de forma independente em cada GPU. Após o cálculo do gradiente, é preciso combinar os gradientes calculados e enviar o resultado para cada GPU. Essa operação é chamada de *allreduce*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 224, 224]) cuda:0\n",
      "torch.Size([8, 1, 224, 224]) cpu\n"
     ]
    }
   ],
   "source": [
    "def scatter(x, devices):\n",
    "    '''Divide um batch em n diferentes dispositivos.'''\n",
    "\n",
    "    n = len(devices)\n",
    "    # .chunk(n) divide o batch em n minibatches de tamanho bs/n\n",
    "    x_shard = list(x.chunk(n))\n",
    "    # Envia cada minibatch para o dispositivo correto\n",
    "    for idx in range(n):\n",
    "        x_shard[idx] = x_shard[idx].to(devices[idx])\n",
    "\n",
    "    return x_shard\n",
    "\n",
    "# Lista de dispositivos\n",
    "devices = [device1, device2]\n",
    "# Batch de 16 imagens\n",
    "x = torch.rand(16, 1, 224, 224)\n",
    "# Divide em 2 minibatches de tamanho 8\n",
    "x_shards = scatter(x, devices)\n",
    "print(x_shards[0].shape, x_shards[0].device)\n",
    "print(x_shards[1].shape, x_shards[1].device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencionado, precisamos de uma operação allreduce para somar os gradientes calculados nas GPUs e enviar o resultado para todas as GPUs. A soma é feita na GPU 0, que recebe os gradientes das outras GPUs, soma os valores, e envia o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([3.], device='cuda:0'), tensor([3.])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def allreduce(grad_shards):\n",
    "    \"\"\"Agrega os valores de gradientes no dispositivo 0 e envia o resultado de \n",
    "    volta para os outros dispositivos.\"\"\"\n",
    "\n",
    "    n = len(grad_shards)\n",
    "    # Soma os valores que estão nos devices 1, 2, 3,... e armazena no device 0\n",
    "    for i in range(1, n):\n",
    "        # Envia o dado para o device 0\n",
    "        x0 = grad_shards[i].to(grad_shards[0].device)\n",
    "        # Soma in-place o valor enviado com o que está no device 0\n",
    "        grad_shards[0][:] += x0\n",
    "\n",
    "    # Envia o resultado para cada device\n",
    "    for i in range(1, n):\n",
    "        xi = grad_shards[0].to(grad_shards[i].device)\n",
    "        grad_shards[i][:] = xi\n",
    "\n",
    "# Exemplo de gradiente em diferentes dispositivos\n",
    "x = torch.tensor([1., 2.])\n",
    "grad_shards = scatter(x, devices)\n",
    "# soma os valores\n",
    "allreduce(grad_shards)\n",
    "# Resultado esperado: o valor 3 em ambos os dispositivos. Note que o dispositivo\n",
    "# de tensores na CPU não são impressos automaticamente\n",
    "grad_shards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop de treinamento\n",
    "\n",
    "Podemos então criar um loop de treinamento. Abaixo faremos apenas o treinamento, sem o passo de validação, que seria similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def get_dataset():\n",
    "    '''Gambiarra para simular um dataloader de segmentação com 10 batches. Cada \n",
    "    batch possui 16 imagens de 1 canal e 16 imagens de target com valor 0'''\n",
    "\n",
    "    images = torch.rand(10, 16, 1, 224, 224)\n",
    "    targets = torch.zeros(10, 16, 224, 224, dtype=torch.long)\n",
    "    dl = list(zip(images, targets))\n",
    "    \n",
    "    return dl\n",
    "\n",
    "def train(model, dl, devices):\n",
    "\n",
    "    # Copia o modelo para cada GPU\n",
    "    models = [copy.deepcopy(model).to(device) for device in devices]\n",
    "    # Lista de parâmetros de cada modelo, note que os parâmetros estão\n",
    "    # em dispositivos diferentes\n",
    "    params_devs = [list(model.parameters()) for model in models]\n",
    "    # Cria uma lista flat para o otimizador\n",
    "    params_all = [param for params in params_devs for param in params]\n",
    "    optim = torch.optim.SGD(params_all)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        print(epoch)\n",
    "        for x_b, t_b in dl:\n",
    "            optim.zero_grad()\n",
    "            # Divide os dados entre as GPUs\n",
    "            x_shards = scatter(x_b, devices)\n",
    "            t_shards = scatter(t_b, devices)\n",
    "            # Aplica o modelo e calcula gradientes em cada GPU\n",
    "            for model, x_shard, t_shard in zip(models, x_shards, t_shards):\n",
    "                scores = model(x_shard)\n",
    "                loss = loss_func(scores, t_shard)\n",
    "                loss.backward()\n",
    "\n",
    "            # Sincroniza os dispositivos para evitar copiar gradientes \n",
    "            # do batch anterior\n",
    "            torch.cuda.synchronize()\n",
    "            # Soma o gradiente de cada parâmetro na GPU 0 e copia o resultado\n",
    "            # para todas as GPUs\n",
    "            num_params = len(params_devs[0])\n",
    "            for param_idx in range(num_params):\n",
    "                grad_shards = []\n",
    "                for params in params_devs:\n",
    "                    # `params` são os parâmetros do modelo em uma GPU\n",
    "                    # `params[param_idx]` é um parâmetro específico do modelo\n",
    "                    grad_shards.append(params[param_idx].grad)\n",
    "                # Soma os gradientes e copia entre os modelos\n",
    "                with torch.no_grad():\n",
    "                    allreduce(grad_shards)\n",
    "\n",
    "            # Atualiza os parâmetros\n",
    "            optim.step()\n",
    "\n",
    "dl = get_dataset()\n",
    "# `model`` pode ser qualquer modelo (ResNet, ViT, etc). Vamos fingir que uma camada\n",
    "# conv é o nosso modelo\n",
    "model = nn.Conv2d(1,1,1)\n",
    "train(model, dl, devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código que implementamos é preciso tomar cuidado com camadas BatchNorm. A camada BatchNorm calcula as estatísticas de cada batch, mas elas estão sendo calculadas de forma independente em cada GPU. Essa camada conhecidamente é problemática em paralelização. Uma estratégia é além de compartilhar gradientes compartilhar também os parâmetros do batch norm. É comum também utilizar a camada LayerNorm ao invés de BatchNorm, pois ela não possui esse problema.\n",
    "\n",
    "Há um gargalo na nossa implementação, toda a lógica é orquestrada por um único processo da CPU. Em uma implementação completamente paralela, são criados n processos para n GPUs, e cada processo se comunica com a respectiva GPU. Há uma implementação desse procedimento na classe **nn.parallel.DistributedDataParallel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visão geral sobre opções de paralelismo e escalabilidade\n",
    "\n",
    "* Pipeline parallelism (PP): Consiste em executar diferentes camadas de um modelo em diferentes GPUs. Primeiro exemplo deste notebook.\n",
    "\n",
    "* Data Parallelism (DP): Consiste em replicar um modelo em múltiplas GPUs. Cada GPU processa um batch diferente de dados. É necessário agregar os gradientes entre as GPUs (implementado acima). Cada GPU precisa ter memória suficiente para executar o modelo. O caso de apenas um processo na CPU é implementado pela camada nn.DataParallel do Pytorch. \n",
    "\n",
    "* Distributed Data Parallelism (DDP): O mesmo que DataParallel, mas é criado um processo distinto na CPU para cada GPU, o que evita gargalos. A classe to Pytorch nn.parallel.DistributedDataParallel possui uma implementação dessa estratégia. As bibliotecas Accelerate e Fabric permitem implementar essa estratégia de forma simples em um loop de treinamento. \n",
    "\n",
    "* Model Parallelism (MP): As camadas de um modelo são divididas entre GPUs. Por exemplo, metade da matriz de uma camada linear fica em uma GPU e metade na outra. Essa estratégia permite executar modelos que não cabem em uma GPU, mas como é necessário muita comunicação entre GPUs, a velocidade de processamente tende a ser menor. O modelo AlexNet usou essa estratégia, já que a GPU utilizada possuía apenas 3GB\n",
    "\n",
    "* Fully Sharded Data Parallel (FSDP): Conceito que divide os parâmetros e gradientes do modelo e estados do otimizador em diversas partes (shards), que são alocadas em GPUs distintas. Cada GPU executa apenas parte do método .forward e dos cálculos do gradiente. Isso permite ganhar o benefício do paralelismo de dados do DP e também executar modelos enormes com centenas de GB de tamanho. A biblioteca DeepSpeed é a referência atual dessa estratégia.\n",
    "\n",
    "* CPU-disk/Offloading: consiste em enviar partes de parâmetros e ativações do modelo para a RAM ou disco, o que pertmite executar modelos com trilhões de parâmetros. A biblioteca DeepSpeed também é a referência nessa estratégia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
