{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mecanismo de atenção\n",
    "\n",
    "Atenção consiste em combinar diferentes informações sendo processadas por uma rede neural de forma a aumentar o contexto dos atributos. Por exemplo, ao processar uma imagem, filtros de CNNs combinam valores bem locais (ex: regiões 3x3), e são necessárias muitas camadas para que a rede consiga combinar regiões distintias de uma imagem. Mecanismos de atenção podem ser utilizados para combinar regiões distantes de uma imagem, o que permite que cada região seja processada com um contexto global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação de uma imagem em uma sequência de tokens\n",
    "\n",
    "A atenção espacial consiste em transformar regiões da imagem em tokens. Esses tokens não possuem uma posição espacial, eles são tratados como um *bag of tokens* que podem ser combinados de forma independente, sem levar em conta a proximidade entre eles. Tokens são exatamente o mesmo conceito encontrado em processamento de língua natural (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 196, 768])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class PatchifyLayer(nn.Module):\n",
    "    \"\"\"Módulo que transforma uma imagem em um conjunto de tokens.\"\"\"\n",
    "        \n",
    "    def __init__(self, image_size, patch_size, token_dim):\n",
    "        \"\"\"`image_size` precisa ser divisível por `patch_size`.\n",
    "\n",
    "        Args:\n",
    "            image_size (int): tamanho da imagem que será processada.\n",
    "            patch_size (int): tamanho das regiões que serão transformada em tokens.\n",
    "            token_dim (int): número de atributos gerados para cada token.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Note o stride. Essa camada transforma cada região patch_size x patch_size \n",
    "        # da imagem em token_dim x 1 x 1\n",
    "        self.conv_proj = nn.Conv2d(\n",
    "            3, token_dim, kernel_size=patch_size, stride=patch_size\n",
    "        )\n",
    "\n",
    "        # Novo tamanho da imagem\n",
    "        new_size = image_size//patch_size\n",
    "        # Tamanho da sequência de tokens\n",
    "        seq_length = new_size**2\n",
    "\n",
    "        self.token_dim = token_dim\n",
    "        self.new_size = new_size\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # (bs, c, image_size, image_size) -> (bs, token_dim, new_size, new_size)\n",
    "        x = self.conv_proj(x)\n",
    "        # (bs, token_dim, new_size, new_size) -> (bs, token_dim, (new_size*new_size))\n",
    "        x = x.reshape(x.shape[0], self.token_dim, -1)\n",
    "        # Coloca a dimensão espacial como segunda, pois o padrão de camadas de \n",
    "        # atenção é bs x seq_length x token_dim\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "# 8 imagens RGB de tamanho 224 x 224\n",
    "x = torch.rand(8, 3, 224, 224)\n",
    "pl = PatchifyLayer(image_size=224, patch_size=16, token_dim=768)\n",
    "tokens = pl(x)\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagem em um batch é representada por 196 tokens, cada um possuindo 768 atributos\n",
    "\n",
    "#### Nota: Multiplicação matricial em batches\n",
    "\n",
    "No que faremos no restante deste notebook, será importante entender como uma sequência de tokens pode ser processada em batches em uma camada linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado de entrada\n",
    "x = torch.rand(196, 768)\n",
    "# Matrix de pesos\n",
    "w = torch.rand(768, 64)\n",
    "\n",
    "# Multiplicação matricial, o resultado possuirá tamanho:\n",
    "# 196x768 * 768x64 -> 196x64\n",
    "y = torch.matmul(x, w)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Pytorch possibilita realizar multiplicação matricial em batches, por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 12, 196, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado de entrada\n",
    "x = torch.rand(8, 12, 196, 768)\n",
    "# Matrix de pesos\n",
    "w = torch.rand(768, 64)\n",
    "\n",
    "# 8x12x196x768 * 768x64 -> 8x12x196x64\n",
    "y = torch.matmul(x, w)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código acima é equivalente a fazer algo como:\n",
    "\n",
    "```python\n",
    "y = torch.zeros(8, 12, 196, 64)\n",
    "for idx_dim1 in range(8):\n",
    "    for idx_dim2 in range(12):\n",
    "        y[idx_dim1,idx_dim2] = torch.matmul(x[idx_dim1,idx_dim2], w)\n",
    "```\n",
    "\n",
    "O mesmo ocorre para camadas lineares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 12, 196, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(768, 64)\n",
    "y = linear(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operação de atenção\n",
    "\n",
    "Tendo a imagem representada como uma sequência, podemos aplicar um mecanismo de atenção à imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 196, 768])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attention(query, key, value):\n",
    "    \n",
    "    # Tamanho de cada token\n",
    "    d_k = query.shape[-1]\n",
    "    # Similaridade entre cada par de tokens da sequência\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / d_k**0.5\n",
    "    # Normaliza a similaridade entre [0,1]\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    # Atualiza os valores dos tokens de acordo com as similaridades\n",
    "    value = torch.matmul(p_attn, value)\n",
    "\n",
    "    return value\n",
    "\n",
    "out = attention(tokens, tokens, tokens)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a operação de atenção não possui parâmetros treináveis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atenção com múltiplas cabeças\n",
    "\n",
    "O artigo original sobre atenção define a chamada multi-head attention, que consiste em realizar diversas atenções em paralelo para aumentar o poder de expressividade do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 196, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, heads, token_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # Valor usado para normalização\n",
    "        d_k = token_dim//heads\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "        # Camadas de projeção antes da atenção\n",
    "        self.proj_query = nn.Linear(token_dim, token_dim)\n",
    "        self.proj_key = nn.Linear(token_dim, token_dim)\n",
    "        self.proj_value = nn.Linear(token_dim, token_dim)\n",
    "        self.final = nn.Linear(token_dim, token_dim)\n",
    "\n",
    "    def proj_and_reshape(self, layer, x):\n",
    "        '''Aplica uma transformação linear e redimensiona o resultado\n",
    "        para ser usado na função de atenção.'''\n",
    "\n",
    "        bs = x.shape[0]\n",
    "        # A multiplicação x*layer.weight abaixo possui dimensão:\n",
    "        # (bs x n x token_dim) * (token_dim x heads*d_k)\n",
    "        # onde n é o tamanho da sequência.\n",
    "        # Cada sequência com token_dim (heads*d_k) atributos é multiplicada por \n",
    "        # uma coluna da camada linear. Isso é equivalente a fazer a sequinte operação:\n",
    "        # Aplicar `heads`` camadas, cada uma com tamanho token_dim x d_k, nas sequências\n",
    "        # e depois concatenar os resultados. \n",
    "        x = layer(x)\n",
    "        # Visualiza o resultado como uma matriz bs x heads x n x d_k. Isso\n",
    "        # possibilita aplicar a função `attention` nas dimensões n x d_k\n",
    "        x = x.view(bs, -1, self.heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "\n",
    "        nbatches = query.shape[0]\n",
    "        query_proj = self.proj_and_reshape(self.proj_query, query)\n",
    "        key_proj = self.proj_and_reshape(self.proj_key, key)\n",
    "        value_proj = self.proj_and_reshape(self.proj_value, value)\n",
    "\n",
    "        x = attention(query_proj, key_proj, value_proj)\n",
    "        # Redimensiona de bs x heads x n x d_k para bs x n x token_dim\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.heads*self.d_k)\n",
    "\n",
    "        return self.final(x)\n",
    "    \n",
    "mha = MultiHeadedAttention(heads=12, token_dim=768)\n",
    "out = mha(tokens, tokens, tokens)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Pytorch possui uma camada que faz exatamente o que implementamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 196, 768]) torch.Size([8, 196, 196])\n"
     ]
    }
   ],
   "source": [
    "mha = nn.MultiheadAttention(embed_dim=768, num_heads=12, batch_first=True)\n",
    "out, attn_weights  = mha(tokens, tokens, tokens)\n",
    "print(out.shape, attn_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A camada também retorna a multiplicação entre as chaves e queries (variável `p_attn` na nossa função de atenção). Essa variável é útil para verificar o relacionamento entre os tokens da sequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 768])\n"
     ]
    }
   ],
   "source": [
    "print(mha.in_proj_weight.shape)\n",
    "print(mha.out_proj.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo `in_proj_weight` é a matriz de pesos das projeções das chaves, queries e valores. O Pytorch realiza as projeções em uma única multiplicação matricial. Para fazer isso basta concatenar as matrizes `proj_query`, `proj_key` e `proj_value` da nossa classe. Não fizemos dessa forma para deixar o código mais simples de entender.\n",
    "\n",
    "O atributo `out_proj` é a camada linear de saída que implementamos (`final`)\n",
    "\n",
    "Até o momento utilizamos a chamada *self-attention*, que consiste em utilizar a mesma variável como query, key e value. Mas o mecanismo de atenção pode ser utilizado de forma natural para misturar diferentes informações. Por exemplo, uma camada de atenção pode receber como entrada atributos sobre um texto e sobre uma imagem. Nesse caso, é comum associar `key` e `value` com os atributos do texto e `query` com os atributos da imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 196, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch com 8 sequências de tokens de imagens\n",
    "tokens_img = torch.rand(8, 196, 768)\n",
    "# batch com 8 sequências de tokens de texto, cada texto possui 20 tokens e\n",
    "# cada token 512 atributos. Por exemplo, esses textos podem ser descrições\n",
    "# da imagem como \"Uma imagem de um cachorro dormindo\"\n",
    "tokens_text = torch.rand(8, 20, 768)\n",
    "\n",
    "#              query         key         value\n",
    "out, _ = mha(tokens_img, tokens_text, tokens_text)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os nomes *key*, *value* e *query* referenciam conceitos de banco de dados. Podemos considerar que *key* e *value* representam as chaves e valores de itens de um banco de dados. *query* é uma busca feita no banco. A similaridade entre a busca (*query*) e as chaves (*keys*) é calculada. A busca vai ser mais similar a algumas chaves do que outras. Os elementos mais similares encontrados na busca são usados para atualizar os valores de *value*, e esses valores atualizados são a saída da camada. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
