{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificadores e decodificadores\n",
    "\n",
    "Um codificador extrai atributos de uma imagem em diferentes resoluções. Um decodificador processa esses atributos para extrair uma imagem de mesmo tamanho que a imagem de entrada do codificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um decodificador\n",
    "\n",
    "Iremos criar um decodificar do tipo *Feature Pyramid Network*. Ele recebe uma lista de tensores contendo ativações de camadas de um codificador e combina essas ativações para gerar um único tensor de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 112, 112])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv_norm(in_channels, out_channels, kernel_size=3, act=True):\n",
    "    '''Cria uma camada conv->batchnorm com uma ativação relu opcional.'''\n",
    "\n",
    "    layer = [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                padding=kernel_size//2, bias=False),\n",
    "        nn.BatchNorm2d(out_channels)\n",
    "    ]\n",
    "    if act:\n",
    "        layer += [nn.ReLU()]\n",
    "    \n",
    "    return nn.Sequential(*layer)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    '''Recebe a ativação do nível anterior do decoder `x_dec` e a ativação do \n",
    "    encoder `x_enc`. É assumido que `x_dec` possui uma resolução espacial\n",
    "    menor que `x_enc` e que `x_enc` possui número de canais diferente\n",
    "    de `x_dec`.\n",
    "    \n",
    "    O módulo ajusta a resolução de `x_dec` para ser igual a `x_enc` e o número\n",
    "    de canais de `x_enc` para ser igual a `x_dec`.'''\n",
    "\n",
    "    def __init__(self, enc_channels, dec_channels):\n",
    "        super().__init__()\n",
    "        self.channel_adjust = conv_norm(enc_channels, dec_channels, kernel_size=1,\n",
    "                                        act=False)\n",
    "        self.mix = conv_norm(dec_channels, dec_channels)\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        x_dec_int = F.interpolate(x_dec, size=x_enc.shape[-2:], mode=\"nearest\")\n",
    "        x_enc_ad = self.channel_adjust(x_enc)\n",
    "        y = x_dec_int + x_enc_ad\n",
    "        return self.mix(y)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''Na criação da instância, recebe uma lista com o número de canais das\n",
    "    ativações do codificador. Essa lista é necessária para criação das\n",
    "    camadas de convolução. O método .forward irá receber uma lista de tensores\n",
    "    e gerar uma saída com a resolução do primeiro tensor e número de canais\n",
    "    dado por `decoder_channels`. \n",
    "    \n",
    "    Por exemplo, suponha que as ativações extraídas de um codificador possuem \n",
    "    as dimensões:\n",
    "    \n",
    "    [(64,112,112), (128,56,56), (256,28,28), (512,14,14)]\n",
    "\n",
    "    Então devemos usar `encoder_channels_list=[64, 128, 256, 512]`, e o método\n",
    "    .forward irá gerar um tensor de tamanho (`decoder_channels`,112,112).\n",
    "    '''\n",
    "\n",
    "    def __init__(self, encoder_channels_list, decoder_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # Inverte lista para facilitar interpretação\n",
    "        encoder_channels_list = encoder_channels_list[::-1]\n",
    "\n",
    "        self.middle = conv_norm(encoder_channels_list[0], decoder_channels)\n",
    "        blocks = []\n",
    "        for channels in encoder_channels_list[1:]:\n",
    "            blocks.append(DecoderBlock(channels, decoder_channels))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        # Inverte lista para facilitar interpretação\n",
    "        features = features[::-1]\n",
    "\n",
    "        x = self.middle(features[0])\n",
    "        for idx in range(1, len(features)):\n",
    "            # Temos um bloco a menos do que nro de features, por isso\n",
    "            # o idx-1\n",
    "            x = self.blocks[idx-1](features[idx], x)\n",
    "\n",
    "        return x\n",
    "\n",
    "encoder_channels_list = [64, 128, 256]\n",
    "decoder_channels = 64\n",
    "\n",
    "decoder = Decoder(encoder_channels_list, decoder_channels)\n",
    "# Lista de atributos de teste, representando os atributos extraídos de um\n",
    "# codificador\n",
    "x = [\n",
    "    torch.rand(1, 64, 112, 112), \n",
    "    torch.rand(1, 128, 56, 56), \n",
    "    torch.rand(1, 256, 28, 28)\n",
    "]\n",
    "res = decoder(x)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decodificação de atributos de uma ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"Amostra ativações de um modelo ResNet do Pytorch e cria um decodificador.\"\"\"\n",
    "\n",
    "    def __init__(self, resnet_encoder, decoder_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Codificador\n",
    "        self.resnet_encoder = resnet_encoder\n",
    "        # Extrai lista de canais dos atributos do codificador para criação de\n",
    "        # decodificador\n",
    "        encoder_channels_list = self.get_channels()\n",
    "        # Decodificador\n",
    "        self.decoder = Decoder(encoder_channels_list, decoder_channels)\n",
    "        # Camada final de classificação\n",
    "        self.classification = nn.Conv2d(decoder_channels, num_classes, 3, padding=1)\n",
    "        \n",
    "    def get_features(self, x):\n",
    "        '''Extrai as ativações intermediárias de uma resnet.'''\n",
    "        \n",
    "        features = []\n",
    "        re = self.resnet_encoder\n",
    "        x = re.conv1(x)\n",
    "        x = re.bn1(x)\n",
    "        x = re.relu(x)\n",
    "        features.append(x)\n",
    "        x = re.maxpool(x)\n",
    "\n",
    "        x = re.layer1(x)\n",
    "        features.append(x)\n",
    "        x = re.layer2(x)\n",
    "        features.append(x)\n",
    "        x = re.layer3(x)\n",
    "        features.append(x)\n",
    "        x = re.layer4(x)\n",
    "        features.append(x)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def get_channels(self):\n",
    "        '''Obtém o número de canais de cada tensor de features extraído pelo\n",
    "        encoder.'''\n",
    "\n",
    "        re = self.resnet_encoder\n",
    "        # Armazena se o modelo estava em modo treinamento\n",
    "        training = re.training\n",
    "        re.eval()\n",
    "\n",
    "        x = torch.zeros(1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            features = self.get_features(x)\n",
    "        encoder_channels_list = [f.shape[1] for f in features]\n",
    "\n",
    "        # Volta para treinamento\n",
    "        if training:\n",
    "            re.train()\n",
    "\n",
    "        return encoder_channels_list\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_shape = x.shape[-2:]\n",
    "        features = self.get_features(x)\n",
    "        x = self.decoder(features)\n",
    "\n",
    "        # Interpola o resultado para ter a mesma dimensão que a imagem de entrada\n",
    "        if x.shape[-2:]!=in_shape:\n",
    "            x = F.interpolate(x, size=in_shape, mode=\"nearest\")\n",
    "\n",
    "        x = self.classification(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "encoder = models.resnet18()\n",
    "model = EncoderDecoder(encoder, 64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 224, 224])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 224, 224)\n",
    "y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Medindo a qualidade da segmentação\n",
    "\n",
    "Precisamos de uma medida de performance para quantificar a qualidade da segmentação produzida por um modelo. Uma medida muito popular é a chamada *Intersecção sobre a União* (IoU). A medida consiste em calcular a intersecção entre o resultado do modelo e a imagem de rótulo, e dividir o valor resultante pela união das regiões definidas pelas duas imagens. Veremos também como calcular a precisão, revocação e acurácia dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4988), tensor(0.1464), tensor(0.4945), tensor(0.1721))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metrics(scores, targets, ignore_val=2):\n",
    "    '''Função que calcula a Intersecção sobre a União entre o resultado\n",
    "    da rede e o rótulo conhecido.'''\n",
    "\n",
    "    # Transforma a predição da rede em índices 0 e 1, e aplica em reshape\n",
    "    # nos tensores para transformá-los em 1D\n",
    "    pred = scores.argmax(dim=1).reshape(-1)\n",
    "    targets = targets.reshape(-1)\n",
    "\n",
    "    # Mantém apenas valores para os quais target!=2. O valor 2 indica píxeis\n",
    "    # a serem ignorados\n",
    "    pred = pred[targets!=ignore_val]\n",
    "    targets = targets[targets!=ignore_val]\n",
    "\n",
    "    # Verdadeiro positivos\n",
    "    tp = ((targets==1) & (pred==1)).sum()\n",
    "    # Verdadeiro negativos\n",
    "    tn = ((targets==0) & (pred==0)).sum()\n",
    "    # Falso positivos\n",
    "    fp = ((targets==0) & (pred==1)).sum()\n",
    "    # Falso negativos\n",
    "    fn = ((targets==1) & (pred==0)).sum()\n",
    "\n",
    "    # Algumas métricas interessantes para medir a qualidade do resultado\n",
    "    # Fração de píxeis corretos\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    # Intersecção sobre a união (IoU)\n",
    "    iou = tp/(tp+fp+fn)\n",
    "    # Precisão\n",
    "    prec = tp/(tp+fp)\n",
    "    # Revocação\n",
    "    rev = tp/(tp+fn)\n",
    "\n",
    "    return acc, iou, prec, rev\n",
    "\n",
    "# Batch de imagens artificial\n",
    "imgs = torch.rand(8, 3, 224, 224)\n",
    "# Targets artificiais, com valores 0, 1 e 2\n",
    "targets = torch.randint(0, 3, (8, 224, 224))\n",
    "scores = model(imgs)\n",
    "metrics(scores, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
