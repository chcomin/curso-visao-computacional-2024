{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diferenciação automática\n",
    "\n",
    "A diferenciação automática é uma técnica para calcular e propagar derivadas usando a regra da cadeia, que é a principal operação de qualquer rede neural usando o algoritmo de retropropagação e gradiente descendente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferenciação automática utilizando Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Cria um tensor com valor 1. requires_grad=True significa que queremos\n",
    "# calcular o gradiente em relação a essa variável.\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "y = 4*x**2\n",
    "\n",
    "# Calcula o gradiente de y em relação à todas as variáveis que foram foram utilizadas para\n",
    "# definir y e que possuem requires_grad=True (variável folha). Nesse caso, será calculado\n",
    "# o gradiente de y em relação à x.\n",
    "y.backward()\n",
    "\n",
    "# A componente dy/dx do gradiente é armazenada como o atributo .grad da variável x\n",
    "dydx = x.grad\n",
    "\n",
    "# dydx = 8*x = 8\n",
    "print(dydx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos calcular o gradiente para uma expressão mais complexa:\n",
    "\n",
    "$\n",
    "\\large\n",
    "y = x_1*x_2 + x_3^2 - \\frac{x_4}{x_2}\n",
    "$\n",
    "\n",
    "O gradiente de y é dado por\n",
    "\n",
    "$\n",
    "\\large\n",
    "\\nabla y = (\\frac{\\partial{y}}{\\partial{x1}}, \\frac{\\partial{y}}{\\partial{x2}}, \\frac{\\partial{y}}{\\partial{x3}}, \\frac{\\partial{y}}{\\partial{x4}})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(2.4444)\n",
      "tensor(2.)\n",
      "tensor(-0.3333)\n"
     ]
    }
   ],
   "source": [
    "def function(x1, x2, x3, x4):\n",
    "    \n",
    "    y = x1*x2 + x3**2 - x4/x2\n",
    "    return y\n",
    "\n",
    "def gradient(y, x1, x2, x3, x4):\n",
    "    \n",
    "    y.backward()\n",
    "    gradient = [x1.grad, x2.grad, x3.grad, x4.grad]\n",
    "    return gradient\n",
    "\n",
    "x1 = torch.tensor(2., requires_grad=True)\n",
    "x2 = torch.tensor(3., requires_grad=True)\n",
    "x3 = torch.tensor(1., requires_grad=True)\n",
    "x4 = torch.tensor(4., requires_grad=True)\n",
    "\n",
    "y = function(x1, x2, x3, x4)\n",
    "grad = gradient(y, x1, x2, x3, x4)\n",
    "\n",
    "dydx1, dydx2, dydx3, dydx4 = grad\n",
    "\n",
    "# dydx1 = x2 = 3\n",
    "print(dydx1)\n",
    "\n",
    "# dydx2 = x1 + x4/x2**2 = 2 + 4/9 = 2.4444\n",
    "print(dydx2)\n",
    "\n",
    "# dydx3 = 2*x3 = 2\n",
    "print(dydx3)\n",
    "\n",
    "# dydx4 = -1/x2 = -0.33333\n",
    "print(dydx4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também calcular o gradiente de funções compostas, isto é, funções (ou variáveis) que dependem de outras funções:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "& y(x) = 3*x^2 \\\\\n",
    "& z(y) = y^4 \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\frac{\\partial{z}}{\\partial{x}} & = \\frac{\\partial{z}}{\\partial{y}}\\frac{\\partial{z}}{\\partial{x}} \\\\\n",
    "\\frac{\\partial{z}}{\\partial{x}} & = 4*y^3 * 6*x\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(82944.)\n",
      "tensor(6912.)\n"
     ]
    }
   ],
   "source": [
    "def y_func(x):\n",
    "    return 3*x**2\n",
    "\n",
    "def z_func(y):\n",
    "    return y**4\n",
    "\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = y_func(x)\n",
    "z = z_func(y)\n",
    "\n",
    "# Por padrão, o Pytorch mantém apenas o gradiente de variáveis folha (x no nosso caso).\n",
    "# Para podermos acessar o gradiente precisamos indicar explicitamente que queremos\n",
    "# manter o gradiente da variável usando o método .retain_grad()\n",
    "y.retain_grad() \n",
    "z.backward()\n",
    "\n",
    "# dzdx = 4*y**3*6*x = (4*12**3)*6*2 = 82944\n",
    "print(x.grad)\n",
    "\n",
    "# dzdy = 4*y**3 = 4*12**3 = 6912\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detalhes importantes ao trabalhar com o Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acúmulo de gradientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "tensor(11.)\n",
      "tensor(13.)\n",
      "tensor(21.)\n"
     ]
    }
   ],
   "source": [
    "# Parâmetro do modelo\n",
    "w = torch.tensor(1., requires_grad=True)\n",
    "# Dados de entrada\n",
    "data = [4, 7, 2, 8]\n",
    "# Ilustração de parte de um loop de treinamento. Para cada dado, calculamos a saída e o gradiente.\n",
    "for x in data:\n",
    "    y = w*x\n",
    "    y.backward()\n",
    "    print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o gradiente está sempre aumentando, o que não é o esperado. Isso ocorre porque o Pytorch **sempre acumula os gradientes** a cada vez que o método .backward() é chamado. Em outras palavras, ele faz algo como:\n",
    "\n",
    "dydx = calculate_gradient(y, x)\n",
    "x.grad += dydx\n",
    "\n",
    "Se não desejamos acumular os gradientes, o que é o caso em geral, devemos sempre apagar os gradientes antes de chamar .backward():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "tensor(7.)\n",
      "tensor(2.)\n",
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(1., requires_grad=True)\n",
    "data = [4, 7, 2, 8]\n",
    "for x in data:\n",
    "    # Remove o gradiente anteriormente computado, se existir. Poderíamos também utilizar\n",
    "    # w.grad = torch.tensor(0.), mas atribuir a None proporciona uma performance um poco melhor\n",
    "    w.grad = None\n",
    "    y = w*x\n",
    "    y.backward()\n",
    "    print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modificando um tensor que possui requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m*\u001b[39mx\n\u001b[0;32m      9\u001b[0m y\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "w = torch.tensor(1., requires_grad=True)\n",
    "data = [4, 7, 2, 8]\n",
    "lr = 0.1\n",
    "# Ilustração de parte de um loop de treinamento, agora também com a atualização do\n",
    "# parâmetro do modelo de acordo com o gradiente calculado. \n",
    "for x in data:\n",
    "    w.grad = None\n",
    "    y = w*x\n",
    "    y.backward()\n",
    "    w -= lr*w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código acima dá erro. A princípio o erro pode parecer confuso, mas podemos entendê-lo ao pensar no grafo que o Pytorch constrói para calcular os gradientes.\n",
    "\n",
    "O termo **leaf variable** está relacionado à variável `w`. Ela é chamada de variável folha porque ela não é calculada a partir de outras variáveis, isto é, ela é definida com um valor inicial utilizando a função torch.tensor(). O Pytorch precisa saber o valor dessa variável ao calcular os gradientes, pois ele pode ser necessário ao aplicar a regra da cadeia.\n",
    "\n",
    "A operação `w -= valor` é uma operação in-place. Ela modifica o valor do tensor. Com isso, se o Pytorch permitisse essa operação, não teria como ele acessar o valor da variável. Por isso ele evita que isso ocorra dando erro.\n",
    "\n",
    "Ao invés de usar `w -= valor`, poderíamos atualizar o valor de outra forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\appdn\\AppData\\Local\\Temp\\ipykernel_3152\\3089122216.py:8: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  w = w - lr*w.grad\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m*\u001b[39mx\n\u001b[0;32m      7\u001b[0m y\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m----> 8\u001b[0m w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m-\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(1., requires_grad=True)\n",
    "data = [4, 7, 2, 8]\n",
    "lr = 0.1\n",
    "for x in data:\n",
    "    w.grad = None\n",
    "    y = w*x\n",
    "    y.backward()\n",
    "    w = w - lr*w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erro novamente? Agora o problema é outro. É importante lembrar que qualquer operação envolvendo um tensor que requer gradiente é armazenada no grafo de computação. Ao fazer `w = w - lr*w.grad`, estamos criando uma nova variável chamada `w` cujo valor é dado por `w - lr*w.grad`. Isso faz com que `w` não seja mais uma variável folha, e não podemos mais acessar o atributo .grad dela.\n",
    "\n",
    "Mais importante, não tem porque registrarmos a operação `w = w - lr*w.grad` no grafo de computação. Queremos apenas atualizar o valor do gradiente. Essa operação nunca será utilizada no cálculo de gradiente. Portanto, para essa operação em particular, devemos evitar de registrá-la no grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6000, requires_grad=True)\n",
      "tensor(-0.1000, requires_grad=True)\n",
      "tensor(-0.3000, requires_grad=True)\n",
      "tensor(-1.1000, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(1., requires_grad=True)\n",
    "data = [4, 7, 2, 8]\n",
    "lr = 0.1\n",
    "for x in data:\n",
    "    w.grad = None\n",
    "    y = w*x\n",
    "    y.backward()\n",
    "    # Contexto Python. Todo código dentro do contexto não será registrado para o \n",
    "    # cálculo do gradiente\n",
    "    with torch.no_grad():\n",
    "        w -= lr*w.grad\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copiando dados e removendo um tensor do grafo de computação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, requires_grad=True)\n",
    "\n",
    "# Copia os dados de x para y. Note que a cópia é incluída no grafo de computação. \n",
    "y = torch.clone(x)\n",
    "\n",
    "# Define um novo tensor, removendo ele do cálculo de gradientes. Importante! Os dados\n",
    "# dos dois tensores são compartilhados. Não modifique o tensor y, pois pode levar\n",
    "# a erros no cálculo do gradiente\n",
    "y = x.detach()\n",
    "\n",
    "# Remove o tensor do grafo e copia os valores. Comando ideal para copiar valores\n",
    "y = x.detach().clone()\n",
    "\n",
    "# Equivalente ao código acima\n",
    "with torch.no_grad():\n",
    "    y = x.clone()\n",
    "\n",
    "# Não recomendado. Cria um novo tensor com requires_grad=False copiando os dados de x \n",
    "#y = torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(100, requires_grad=True)\n",
    "print(x.requires_grad)\n",
    "\n",
    "# Remove o tensor do grafo\n",
    "x.requires_grad = False\n",
    "\n",
    "# Equivalente ao comando acima \n",
    "x.requires_grad_(False)\n",
    "\n",
    "# Conversão entre o pytorch e numpy. Importante! As variáveis compartilham a memória. \n",
    "# A alteração em uma variável altera a outra. Outra coisa, a conversão dará erro se\n",
    "# o tensor possuir requires_grad=True\n",
    "y = x.numpy()\n",
    "z = torch.from_numpy(y)\n",
    "\n",
    "# Tensores possuindo um único valor podem ser transformados em um valor Python\n",
    "# através do método .item()\n",
    "soma = x.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de implementação de diferenciação automática\n",
    "\n",
    "A célula abaixo utiliza uma classe bem simples chamada `Value` que mostra como implementar diferenciação automática. Não é necessário executar ela para executar o resto do notebook. Ela está aqui apenas para mostrar como a diferenciação automática pode ser implementada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1098pt\" height=\"210pt\"\n",
       " viewBox=\"0.00 0.00 1097.50 210.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-206 1093.5,-206 1093.5,4 -4,4\"/>\n",
       "<!-- 1684286830592 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1684286830592</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.75,-165.5 6.75,-201.5 174.5,-201.5 174.5,-165.5 6.75,-165.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"46.62\" y=\"-178.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 5.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"86.5,-166 86.5,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-178.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 72.0000</text>\n",
       "</g>\n",
       "<!-- 1684284204736* -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1684284204736*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"244.25\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"244.25\" y=\"-123.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 1684286830592&#45;&gt;1684284204736* -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>1684286830592&#45;&gt;1684284204736*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.58,-165.04C164.94,-162.34 173.34,-159.46 181.25,-156.5 191.21,-152.77 201.84,-148.19 211.44,-143.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.76,-147.08 220.36,-139.7 209.82,-140.73 212.76,-147.08\"/>\n",
       "</g>\n",
       "<!-- 1684395114576 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1684395114576</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-55.5 0,-91.5 181.25,-91.5 181.25,-55.5 0,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.25\" y=\"-68.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 10.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"86.5,-56 86.5,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.88\" y=\"-68.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 168.0000</text>\n",
       "</g>\n",
       "<!-- 1684395116304* -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>1684395116304*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"244.25\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"244.25\" y=\"-68.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 1684395114576&#45;&gt;1684395116304* -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>1684395114576&#45;&gt;1684395116304*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.58,-73.5C189.93,-73.5 198.05,-73.5 205.5,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"205.46,-77 215.46,-73.5 205.46,-70 205.46,-77\"/>\n",
       "</g>\n",
       "<!-- 1684284204736 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1684284204736</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"307.25,-110.5 307.25,-146.5 481.75,-146.5 481.75,-110.5 307.25,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"350.5\" y=\"-123.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 15.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"393.75,-111 393.75,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.75\" y=\"-123.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 24.0000</text>\n",
       "</g>\n",
       "<!-- 1684395115776+ -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>1684395115776+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"544.75\" cy=\"-100.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"544.75\" y=\"-95.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 1684284204736&#45;&gt;1684395115776+ -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>1684284204736&#45;&gt;1684395115776+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M482.17,-112.13C490.92,-110.48 499.43,-108.87 507.19,-107.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"507.67,-110.88 516.85,-105.58 506.38,-104 507.67,-110.88\"/>\n",
       "</g>\n",
       "<!-- 1684284204736*&#45;&gt;1684284204736 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1684284204736*&#45;&gt;1684284204736</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271.41,-128.5C278.6,-128.5 286.85,-128.5 295.58,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"295.36,-132 305.36,-128.5 295.36,-125 295.36,-132\"/>\n",
       "</g>\n",
       "<!-- 1684395041008 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1684395041008</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3.38,-110.5 3.38,-146.5 177.88,-146.5 177.88,-110.5 3.38,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.25\" y=\"-123.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 3.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83.12,-111 83.12,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-123.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 120.0000</text>\n",
       "</g>\n",
       "<!-- 1684395041008&#45;&gt;1684284204736* -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1684395041008&#45;&gt;1684284204736*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178.07,-128.5C187.65,-128.5 197,-128.5 205.49,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"205.35,-132 215.35,-128.5 205.35,-125 205.35,-132\"/>\n",
       "</g>\n",
       "<!-- 1684395115776 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>1684395115776</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"607.75,-82.5 607.75,-118.5 782.25,-118.5 782.25,-82.5 607.75,-82.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"651\" y=\"-95.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 85.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"694.25,-83 694.25,-118.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"738.25\" y=\"-95.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 24.0000</text>\n",
       "</g>\n",
       "<!-- 1684395114768* -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>1684395114768*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"845.25\" cy=\"-72.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"845.25\" y=\"-67.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 1684395115776&#45;&gt;1684395114768* -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>1684395115776&#45;&gt;1684395114768*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M782.67,-84.13C791.42,-82.48 799.93,-80.87 807.69,-79.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"808.17,-82.88 817.35,-77.58 806.88,-76 808.17,-82.88\"/>\n",
       "</g>\n",
       "<!-- 1684395115776+&#45;&gt;1684395115776 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1684395115776+&#45;&gt;1684395115776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M571.91,-100.5C579.1,-100.5 587.35,-100.5 596.08,-100.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"595.86,-104 605.86,-100.5 595.86,-97 595.86,-104\"/>\n",
       "</g>\n",
       "<!-- 1684395114768 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>1684395114768</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"908.25,-54.5 908.25,-90.5 1089.5,-90.5 1089.5,-54.5 908.25,-54.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"958.25\" y=\"-67.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 2040.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1008.25,-55 1008.25,-90.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1048.88\" y=\"-67.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 1684395114768*&#45;&gt;1684395114768 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1684395114768*&#45;&gt;1684395114768</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M872.66,-72.5C879.82,-72.5 888.02,-72.5 896.72,-72.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"896.46,-76 906.46,-72.5 896.46,-69 896.46,-76\"/>\n",
       "</g>\n",
       "<!-- 1684395116304 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>1684395116304</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"307.25,-55.5 307.25,-91.5 481.75,-91.5 481.75,-55.5 307.25,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"350.5\" y=\"-68.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 70.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"393.75,-56 393.75,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.75\" y=\"-68.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 24.0000</text>\n",
       "</g>\n",
       "<!-- 1684395116304&#45;&gt;1684395115776+ -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>1684395116304&#45;&gt;1684395115776+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M482.17,-89.28C490.92,-90.88 499.43,-92.43 507.19,-93.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"506.38,-97.25 516.85,-95.6 507.64,-90.37 506.38,-97.25\"/>\n",
       "</g>\n",
       "<!-- 1684395116304*&#45;&gt;1684395116304 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1684395116304*&#45;&gt;1684395116304</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271.41,-73.5C278.6,-73.5 286.85,-73.5 295.58,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"295.36,-77 305.36,-73.5 295.36,-70 295.36,-77\"/>\n",
       "</g>\n",
       "<!-- 1684285551488 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>1684285551488</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3.38,-0.5 3.38,-36.5 177.88,-36.5 177.88,-0.5 3.38,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.25\" y=\"-13.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 7.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"83.12,-1 83.12,-36.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-13.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 240.0000</text>\n",
       "</g>\n",
       "<!-- 1684285551488&#45;&gt;1684395116304* -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>1684285551488&#45;&gt;1684395116304*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.63,-36.91C162.94,-39.95 172.39,-43.2 181.25,-46.5 191.08,-50.16 201.6,-54.56 211.14,-58.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"209.45,-61.81 220.01,-62.68 212.29,-55.42 209.45,-61.81\"/>\n",
       "</g>\n",
       "<!-- 1684395115920 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>1684395115920</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"607.75,-27.5 607.75,-63.5 782.25,-63.5 782.25,-27.5 607.75,-27.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"651\" y=\"-40.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 24.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"694.25,-28 694.25,-63.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"738.25\" y=\"-40.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 85.0000</text>\n",
       "</g>\n",
       "<!-- 1684395115920&#45;&gt;1684395114768* -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>1684395115920&#45;&gt;1684395114768*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M782.67,-61.28C791.42,-62.88 799.93,-64.43 807.69,-65.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"806.88,-69.25 817.35,-67.6 808.14,-62.37 806.88,-69.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1882dc5c230>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autodiff import Value, draw_dot\n",
    "\n",
    "x1 = Value(5.0)\n",
    "x2 = Value(7.0)\n",
    "y = 3*x1 + 10*x2\n",
    "z = 24*y\n",
    "z.backward()\n",
    "draw_dot(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão linear usando diferenciação automática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18830b6cd40>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, a, b):\n",
    "\n",
    "        # Parâmetros do modelo\n",
    "        self.a = torch.tensor(a, requires_grad=True)\n",
    "        self.b = torch.tensor(b, requires_grad=True)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = self.a*x + self.b\n",
    "        return  y\n",
    "\n",
    "def mse(model, x, y):\n",
    "\n",
    "    ym = model(x)\n",
    "    error = torch.mean((y-ym)**2)\n",
    "\n",
    "    return error\n",
    "\n",
    "def step(model, x, y, lr):\n",
    "\n",
    "    # Apaga os gradientes\n",
    "    model.a.grad = None\n",
    "    model.b.grad = None\n",
    "    error = mse(model, x, y)\n",
    "    # Calcula os gradientes\n",
    "    error.backward()\n",
    "    # Atualiza os gradientes\n",
    "    with torch.no_grad():\n",
    "        model.a -= lr*model.a.grad\n",
    "        model.b -= lr*model.b.grad\n",
    "\n",
    "    return error.item()\n",
    "\n",
    "data = torch.from_numpy(np.loadtxt('../data/age_data_1.txt'))\n",
    "x, y = data.T\n",
    "\n",
    "model = Model(a=0., b=0.)\n",
    "num_epochs = 100\n",
    "lr = 0.3\n",
    "errors = []\n",
    "for epoch in range(0, num_epochs):\n",
    "    error = step(model, x, y, lr)\n",
    "    errors.append(error)\n",
    "\n",
    "plt.plot(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
