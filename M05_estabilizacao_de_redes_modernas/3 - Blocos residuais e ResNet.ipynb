{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes residuais\n",
    "\n",
    "Implementaremos uma **família** de arquiteturas de CNNs que proporcionam resultados estado-da-arte para classificação de imagens. Esses modelos são a atual referência em tarefas de classificação. Eles também são utilizados em tarefas de detecção de objetos, segmentação e diversas outras tarefas de visão computacional.\n",
    "\n",
    "Artigo de referência:\\\n",
    "[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "Veja a seção *Arquiteturas de CNNs* das notas de aula para uma descrição sobre blocos residuais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação básica de um bloco residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 28, 28])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Caminho residual\n",
    "        out += x\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "rb = ResidualBlock(channels=3)\n",
    "x = torch.rand(8, 3, 28, 28)\n",
    "rb(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação geral\n",
    "\n",
    "A camada residual que implementamos possui uma importante limitação. Ela não permite alterar o número de canais ou o tamanho da saída. Faremos uma implementação mais geral que permite isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 28, 28])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Se o número de canais de entrada for diferente do número de canais de saída,\n",
    "        # ou o tamanho espacial da entrada for diferente da saída, não será possível\n",
    "        # realizar a soma \"out += x\" no método forward, pois out e x terão tamanhos\n",
    "        # distintos. Nesse caso, a estratégia usual é criar uma camada de convolução\n",
    "        # com kernel de tamanho 1x1 que ajusta o número de canais e o tamanho da saída\n",
    "        # do atalho.\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            adjust_shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "        else:\n",
    "            adjust_shortcut = None\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.adjust_shortcut = adjust_shortcut\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.adjust_shortcut is None:\n",
    "            x_adj = x\n",
    "        else:\n",
    "            # Ajusta o número de canais e tamanho do caminho residual\n",
    "            x_adj = self.adjust_shortcut(x)\n",
    "\n",
    "        out += x_adj\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "rb = ResidualBlock(3, 16)\n",
    "x = torch.rand(8, 3, 28, 28)\n",
    "rb(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitetura ResNet\n",
    "\n",
    "Podemos agora implementar a arquitetura ResNet, uma das arquiteturas mais utilizadas em CNNs. A implementação que faremos é inspirada na implementação do Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, num_classes, in_channels):\n",
    "        \"\"\"Rede neural residual.\n",
    "\n",
    "        Args:\n",
    "            layers (list): Lista de inteiros contendo o número de camadas em cada\n",
    "            estágio da rede. \n",
    "            num_classes (int): Número de classes para a última camada linear.\n",
    "            in_channels (int): Número de canais das imagens nas quais a rede\n",
    "            será aplicada.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Primeira camada\n",
    "        self.conv = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Pooling inicial para reduzir a resolução\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 4 estágios da ResNet. O primeiro não envolve mudança de canal nem de resolução\n",
    "        # Os demais dobram o número de canais e reduzem a resolução pela metade\n",
    "        self.stage1 = self.make_stage(64, 64, layers[0])\n",
    "        self.stage2 = self.make_stage(64, 128, layers[1], stride=2)\n",
    "        self.stage3 = self.make_stage(128, 256, layers[2], stride=2)\n",
    "        self.stage4 = self.make_stage(256, 512, layers[3], stride=2)\n",
    "        # Fixa a saída em um tensor de tamanho bs x 512 x 1 x 1\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        # Camada de classificação\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_stage(self, in_channels, out_channels, num_blocks, stride=1):\n",
    "        \"\"\"Cria um estágio da ResNet. Um estágio consiste em uma redução na\n",
    "        resolução das ativações (pooling) seguida de camadas de convolução.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Número de canais de entrada\n",
    "            out_channels (int): Número de canais de saída\n",
    "            num_blocks (int): Número de blocos residuais do estágio\n",
    "            stride (int): Stride da primeira convolução do bloco residual. \n",
    "            Quando este parâmetro for 2, a saída do estágio terá metade do\n",
    "            tamanho espacial da entrada.\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        # O primeiro bloco residual muda o número de canais e resolução\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "        # Os demais blocos apenas fazem a convolução\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # Mesmo que x.reshape(x.shape[0], -1)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet18(num_classes, in_channels):\n",
    "     '''O nome resnet18 significa que a rede possui 18 camadas com \n",
    "     parâmetros (17 convolucionais + 1 camada linear final).'''\n",
    "     return ResNet(layers=[2, 2, 2, 2], num_classes=num_classes, in_channels=in_channels)\n",
    "\n",
    "model = resnet18(10, 1)\n",
    "x = torch.rand(8,1,28,28)\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outros modelos da família ResNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(num_classes, in_channels):\n",
    "     '''34 camadas'''\n",
    "     return ResNet(layers=[3, 4, 6, 3], num_classes=num_classes, in_channels=in_channels)\n",
    "\n",
    "def resnet50(num_classes, in_channels):\n",
    "     '''50 camadas'''\n",
    "     return ResNet(layers=[3, 4, 6, 3], num_classes=num_classes, in_channels=in_channels)\n",
    "\n",
    "def resnet101(num_classes, in_channels):\n",
    "     '''101 camadas'''\n",
    "     return ResNet(layers=[3, 4, 23, 3], num_classes=num_classes, in_channels=in_channels)\n",
    "\n",
    "def resnet152(num_classes, in_channels):\n",
    "     '''152 camadas'''\n",
    "     return ResNet(layers=[3, 8, 36, 3], num_classes=num_classes, in_channels=in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: A implementação real do Pytorch usa um bloco residual um pouco diferente para as resnets 50, 101 e 152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos ResNet do Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota: Nos modelos do Pytorch, os atributos que chamamos de .stage1, .stage2, .stage3, .stage4 são chamados de .layer1, .layer2, .layer3 e .layer4**\n",
    "\n",
    "Vamos contar quantas camadas estão presentes nos modelos do Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 11.689512)\n",
      "(34, 21.797672)\n",
      "(50, 25.557032)\n",
      "(101, 44.54916)\n",
      "(152, 60.192808)\n"
     ]
    }
   ],
   "source": [
    "def model_stats(model):\n",
    "    '''Retorna o número de camadas e o número de parâmetros (em milhões) do modelo.'''\n",
    "\n",
    "    layers = 0  # Número de camadas\n",
    "    for name, module in model.named_modules():\n",
    "        # Downsample é o nome do caminho residual usado pelo Pytorch. Removemos\n",
    "        # ele para não contar duas vezes a mesma camada.\n",
    "        if isinstance(module, nn.Conv2d) and 'downsample' not in name:\n",
    "            layers += 1\n",
    "    # Camada linear final\n",
    "    layers += 1\n",
    "\n",
    "    params = 0   # Número de parâmetros\n",
    "    for param in model.parameters():\n",
    "        params += param.numel()\n",
    "\n",
    "    return layers, params/1e6\n",
    "\n",
    "print(model_stats(models.resnet18()))\n",
    "print(model_stats(models.resnet34()))\n",
    "print(model_stats(models.resnet50()))\n",
    "print(model_stats(models.resnet101()))\n",
    "print(model_stats(models.resnet152()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modificação de modelos Pytorch\n",
    "\n",
    "Os modelos disponíveis no Pytorch são implementados para o dataset ImageNet. Portanto cada modelo possui como saída 1000 valores, que é o número de classes do ImageNet. Mas é possível facilmente modificar os modelos para outras tarefas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "# Se imprimirmos o modelo com print(model), veremos que a última camada é \n",
    "# chamada `fc`, ela recebe 512 valores e retorna 1000 valores\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos modificar a última camada para utilizar o modelo em, por exemplo, um\n",
    "# problema de classificação de 2 classes. Para isso, criamos uma nova camada que\n",
    "# recebe como entrada o mesmo número de atributos que o modelo padrão, mas possui\n",
    "# como saída 2 valores.\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
