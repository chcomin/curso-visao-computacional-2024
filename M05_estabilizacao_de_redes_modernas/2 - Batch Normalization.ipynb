{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estabilizando rede neurais - Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas com redes profundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (15): ReLU()\n",
       "    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (19): ReLU()\n",
       "  )\n",
       "  (pool): AdaptiveMaxPool2d(output_size=2)\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def conv3x3(in_channels, out_channels):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    '''Modelo com n camadas convolucionais.'''\n",
    "    def __init__(self, num_layers, features):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [\n",
    "            conv3x3(1,features),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        for idx in range(1, num_layers):\n",
    "            layers.append(conv3x3(features,features))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.pool = nn.AdaptiveMaxPool2d(2)\n",
    "        # Camada linear que recebe features imagens de tamanho 2x2 e gera 10 valores de saída\n",
    "        self.fc = nn.Linear(features*2*2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Além de calcular o resultado, este método retorna as ativações\n",
    "        inermediárias da rede.'''\n",
    "        acts = []\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            acts.append(x)\n",
    "        x = self.pool(x)\n",
    "        # Transformação das imagens de tamanho bs x features x 2 x 2 para bs x features*2*2\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x, acts\n",
    "    \n",
    "model = Model(10, 16)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo diversas vezes com ctrl+enter. A saída da rede é sempre a mesma!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1880, 0.1356, 0.7953, 0.4343, 0.0365, 0.5274, 0.6057, 0.2733, 0.5580,\n",
      "        0.2604, 0.0525, 0.5954, 0.5802, 0.3762, 0.3247, 0.7492, 0.6043, 0.2902,\n",
      "        0.0463, 0.8151, 0.2244, 0.0532, 0.1106, 0.7502, 0.6842, 0.9088, 0.1076,\n",
      "        0.3317])\n",
      "tensor([[-0.0213,  0.0993, -0.0237,  0.0249,  0.0119,  0.0895,  0.0157, -0.1136,\n",
      "         -0.0405,  0.0689]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 1, 28, 28)\n",
    "y, acts = model(x)\n",
    "\n",
    "print(x[0,0,0])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saída da rede é dada apenas pelo bias da última camada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0213,  0.0993, -0.0237,  0.0249,  0.0119,  0.0895,  0.0157, -0.1136,\n",
      "         -0.0405,  0.0689]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.0213,  0.0994, -0.0237,  0.0249,  0.0119,  0.0895,  0.0157, -0.1136,\n",
      "        -0.0405,  0.0689])\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(model.fc.bias.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando a média e desvio padrão das ativações intermediárias da rede, vemos que os valores caem para zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_activations(acts):\n",
    "    act_mean = []\n",
    "    act_std = []\n",
    "    for act in acts:\n",
    "        act = act.detach()\n",
    "        act_mean.append(act.mean())\n",
    "        act_std.append(act.std())\n",
    "\n",
    "    plt.plot(act_mean)\n",
    "    plt.plot(act_std)\n",
    "\n",
    "show_activations(acts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essencialmente, a operação que uma rede neural faz é dada por:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9904e+30, 2.8932e+30, 3.3234e+30, 3.4615e+30, 2.5454e+30, 3.1341e+30,\n",
      "        3.1211e+30, 3.0075e+30, 2.6490e+30, 3.7316e+30])\n"
     ]
    }
   ],
   "source": [
    "# Batch de dados\n",
    "x = torch.rand(10)\n",
    "# Parâmetros das camadas\n",
    "weight = 2.\n",
    "bias = 2.\n",
    "# 100 camadas\n",
    "for i in range(100):\n",
    "    x = (weight*x+bias)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tente achar valores de `weight` e `bias` que não levem o valor de x acima a 0, infinito ou algum valor trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao normalizarmos os valores, as ativações se tornam bem comportadas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3380, -1.1615,  0.6598,  1.6353,  0.2101, -1.1059, -1.1178,  0.7364,\n",
      "         0.7241, -0.9186])\n"
     ]
    }
   ],
   "source": [
    "def normalization(x):\n",
    "    mean = x.mean()\n",
    "    std = x.std()\n",
    "    return (x-mean)/std\n",
    "\n",
    "x = torch.rand(10)\n",
    "weight = 20.\n",
    "bias = -10.\n",
    "for i in range(10):\n",
    "    x = (weight*x+bias)\n",
    "    x = normalization(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas e se a escala dos valores for relevante para a classificação? Por exemplo, talvez um filtro tenda a gerar valores em torno de 10, enquanto que outro filtro gere valores em torno de 0.1. Essa informação será perdida após a normalização.\n",
    "\n",
    "Uma camada batchnorm permite reescalar os valores caso seja necessário. Os parâmetros de escala são aprendidos durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1354,  1.0410,  0.6823,  1.2006, -1.2318,  0.6611,  0.9026, -1.0669,\n",
       "        -0.8861, -0.1673], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # nn.Parameter define um tensor com requires_grad=True e que é registrado \n",
    "        # como parâmetro treinável do modelo\n",
    "        self.gamma = nn.Parameter(torch.tensor(1.))\n",
    "        self.beta = nn.Parameter(torch.tensor(0.))\n",
    "\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        mean = x.mean()\n",
    "        var = x.var()   # Variância\n",
    "        # eps evita divisão por 0\n",
    "        x_norm = (x-mean)/torch.sqrt(var+self.eps)\n",
    "\n",
    "        # Reescala os valores\n",
    "        y = self.gamma*x_norm + self.beta\n",
    "\n",
    "        return y\n",
    "    \n",
    "bn = BatchNorm()\n",
    "bn(100*torch.rand(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas temos um problema. E quando formos aplicar a rede após o treinamento em uma única imagem? Cada camada terá apenas uma única ativação, o que pode ser um problema. Para evitar isso, durante o treinamento podemos armazenar a média e desvio padrão de todos os batches, e usar a estimativa desses parâmetros de todos os batches para normalizar os valores ao aplicar em uma única imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desvendando a camada BatchNorm do Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Batchnorm aplicado em 3 canais\n",
    "bn = nn.BatchNorm1d(3)\n",
    "print(bn.weight)\n",
    "print(bn.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A longo de vários batches, a camada estima a média e variância dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean tensor([0.3976, 0.3957, 0.3768])\n",
      "mean tensor([0.8059, 0.7492, 0.7223])\n",
      "mean tensor([1.1346, 1.0626, 1.0561])\n",
      "mean tensor([1.4222, 1.3861, 1.3661])\n",
      "mean tensor([1.6574, 1.6237, 1.6162])\n",
      "mean tensor([1.9095, 1.8259, 1.8565])\n",
      "mean tensor([2.1217, 2.0394, 2.0852])\n",
      "mean tensor([2.3098, 2.2675, 2.2550])\n",
      "mean tensor([2.4725, 2.4673, 2.3974])\n",
      "mean tensor([2.6355, 2.6099, 2.5412])\n",
      "mean tensor([2.7651, 2.7594, 2.7023])\n",
      "mean tensor([2.8893, 2.8686, 2.8218])\n",
      "mean tensor([2.9997, 2.9632, 2.9677])\n",
      "mean tensor([3.1022, 3.0244, 3.0622])\n",
      "mean tensor([3.2035, 3.0938, 3.1895])\n",
      "mean tensor([3.2991, 3.1593, 3.3072])\n",
      "mean tensor([3.3573, 3.3134, 3.3960])\n",
      "mean tensor([3.4208, 3.3631, 3.4800])\n",
      "mean tensor([3.4661, 3.4020, 3.5291])\n",
      "mean tensor([3.5498, 3.4867, 3.5969])\n",
      "mean tensor([3.6073, 3.5241, 3.6387])\n",
      "mean tensor([3.6699, 3.5395, 3.6787])\n",
      "mean tensor([3.6694, 3.5671, 3.7246])\n",
      "mean tensor([3.6965, 3.6042, 3.7235])\n",
      "mean tensor([3.7274, 3.6424, 3.7647])\n",
      "mean tensor([3.7780, 3.6519, 3.7687])\n",
      "mean tensor([3.7888, 3.6809, 3.7797])\n",
      "mean tensor([3.8073, 3.7113, 3.8068])\n",
      "mean tensor([3.8244, 3.7545, 3.8334])\n",
      "mean tensor([3.8264, 3.7830, 3.8716])\n",
      "mean tensor([3.8300, 3.7889, 3.9141])\n",
      "mean tensor([3.8623, 3.7468, 3.9152])\n",
      "mean tensor([3.8341, 3.7541, 3.9534])\n",
      "mean tensor([3.8434, 3.8015, 3.9856])\n",
      "mean tensor([3.8526, 3.8223, 3.9462])\n",
      "mean tensor([3.8517, 3.8378, 3.9761])\n",
      "mean tensor([3.8438, 3.8401, 3.9668])\n",
      "mean tensor([3.8642, 3.8452, 3.9733])\n",
      "mean tensor([3.8479, 3.9210, 3.9816])\n",
      "mean tensor([3.8947, 3.9096, 3.9903])\n",
      "mean tensor([3.8955, 3.9041, 3.9954])\n",
      "mean tensor([3.9262, 3.9255, 4.0017])\n",
      "mean tensor([3.9330, 3.9506, 4.0147])\n",
      "mean tensor([3.9507, 3.9630, 4.0292])\n",
      "mean tensor([3.9994, 3.9475, 4.0406])\n",
      "mean tensor([3.9959, 3.9229, 4.0301])\n",
      "mean tensor([4.0080, 3.9187, 4.0357])\n",
      "mean tensor([4.0056, 3.9199, 4.0490])\n",
      "mean tensor([4.0450, 3.9415, 4.0420])\n",
      "mean tensor([4.0312, 3.9284, 4.0734])\n",
      "mean tensor([3.9864, 3.9300, 4.0556])\n",
      "mean tensor([3.9589, 3.9266, 4.0431])\n",
      "mean tensor([3.9867, 3.9126, 4.0195])\n",
      "mean tensor([3.9958, 3.9357, 4.0497])\n",
      "mean tensor([4.0244, 3.9635, 4.0662])\n",
      "mean tensor([4.0389, 3.9813, 4.0277])\n",
      "mean tensor([4.0443, 3.9854, 4.0228])\n",
      "mean tensor([4.0306, 4.0075, 4.0448])\n",
      "mean tensor([4.0237, 4.0458, 4.0340])\n",
      "mean tensor([4.0257, 4.0488, 4.0286])\n",
      "mean tensor([3.9949, 4.0516, 4.0343])\n",
      "mean tensor([4.0100, 4.0133, 4.0322])\n",
      "mean tensor([4.0325, 4.0254, 4.0366])\n",
      "mean tensor([4.0273, 4.0158, 4.0170])\n",
      "mean tensor([4.0431, 4.0443, 4.0287])\n",
      "mean tensor([4.0278, 4.0511, 4.0070])\n",
      "mean tensor([3.9898, 4.0301, 4.0204])\n",
      "mean tensor([3.9648, 4.0416, 4.0145])\n",
      "mean tensor([3.9515, 4.0244, 4.0053])\n",
      "mean tensor([3.9637, 4.0306, 4.0410])\n",
      "mean tensor([3.9500, 4.0457, 4.0739])\n",
      "mean tensor([3.9473, 4.0380, 4.0532])\n",
      "mean tensor([3.9204, 4.0270, 4.0257])\n",
      "mean tensor([3.9261, 3.9844, 4.0343])\n",
      "mean tensor([3.9312, 4.0264, 4.0279])\n",
      "mean tensor([3.9750, 4.0034, 4.0117])\n",
      "mean tensor([3.9444, 4.0064, 4.0049])\n",
      "mean tensor([3.9427, 4.0196, 3.9664])\n",
      "mean tensor([3.9514, 4.0353, 3.9674])\n",
      "mean tensor([3.9513, 4.0525, 3.9508])\n",
      "mean tensor([3.9580, 4.0484, 3.9422])\n",
      "mean tensor([3.9604, 4.0425, 3.9365])\n",
      "mean tensor([3.9599, 4.0344, 3.9480])\n",
      "mean tensor([3.9343, 4.0261, 3.9618])\n",
      "mean tensor([3.9482, 4.0090, 3.9556])\n",
      "mean tensor([3.9584, 3.9967, 3.9836])\n",
      "mean tensor([3.9577, 3.9718, 3.9914])\n",
      "mean tensor([3.9809, 3.9848, 4.0180])\n",
      "mean tensor([4.0188, 4.0147, 3.9993])\n",
      "mean tensor([4.0376, 4.0153, 4.0041])\n",
      "mean tensor([4.0377, 3.9962, 4.0020])\n",
      "mean tensor([4.0177, 4.0179, 4.0092])\n",
      "mean tensor([4.0141, 4.0059, 4.0271])\n",
      "mean tensor([4.0095, 4.0380, 4.0357])\n",
      "mean tensor([4.0049, 4.0116, 4.0401])\n",
      "mean tensor([3.9714, 4.0002, 4.0398])\n",
      "mean tensor([3.9976, 3.9988, 4.0543])\n",
      "mean tensor([4.0086, 4.0175, 4.0460])\n",
      "mean tensor([4.0196, 4.0178, 4.0550])\n",
      "mean tensor([4.0207, 4.0025, 4.0268])\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # Batches de 4 elementos, 3 canais cada e 6 valores para cada canal\n",
    "    # Os valores gerados possuem média 4 e variância 9.\n",
    "    x = torch.normal(mean=4, std=1, size=(4,3,6))\n",
    "    _ = bn(x)\n",
    "    print('mean', bn.running_mean)\n",
    "    #print('var', bn.running_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No modo eval, a média estimada é usada quando a camada for aplicada em novos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9248, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Batch de tamanho 1000 com valores de média 10\n",
    "# A média do resultado deve ser aproximadamente 10-bn.running_mean\n",
    "x = torch.normal(mean=10, std=6, size=(1000,3,60))\n",
    "bn.eval()\n",
    "y = bn(x)\n",
    "print(y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retornando o batchnorm para o modo .train faz com que a camada volte a normalizar pela média e desvio do batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.6621e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.normal(mean=10, std=6, size=(1000,3,60))\n",
    "bn.train()\n",
    "y = bn(x)\n",
    "print(y.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
