{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rastreamento de um objeto utilizando o método SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "\n",
    "class RegionSelector:\n",
    "    \"\"\"Classe para capturar o desenho de um retângulo na tela. Utilizada para \n",
    "    capturar a posição inicial de um objeto.\"\"\"\n",
    "    \n",
    "    def __init__(self, img):\n",
    "\n",
    "        self.img = img\n",
    "        self.img2draw = img\n",
    "        self.drawing = False\n",
    "        self.initial_x = -1\n",
    "        self.initial_y = -1\n",
    "        self.end_selection = False\n",
    "\n",
    "        cv2.namedWindow('image')\n",
    "        cv2.setMouseCallback('image', self.draw_rectangle)\n",
    "\n",
    "        while not self.end_selection:\n",
    "            cv2.imshow('image', self.img2draw)\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def draw_rectangle(self, event, x, y, flags, param):\n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.drawing = True\n",
    "            self.initial_x = x\n",
    "            self.initial_y = y\n",
    "\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if self.drawing == True:\n",
    "                ix = self.initial_x\n",
    "                iy = self.initial_y\n",
    "                self.img2draw = self.img.copy()\n",
    "                cv2.rectangle(self.img2draw,(ix,iy),(x,y),(0,255,0),2)\n",
    "\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.drawing = False\n",
    "            ix = self.initial_x\n",
    "            iy = self.initial_y\n",
    "            self.img2draw = self.img.copy()\n",
    "            cv2.rectangle(self.img2draw,(ix,iy),(x,y),(0,255,0),2)\n",
    "\n",
    "            upper_left_x = ix if ix<x else x\n",
    "            upper_left_y = iy if iy < y else y\n",
    "            w = np.abs(ix - x)\n",
    "            h = np.abs(iy - y)\n",
    "            self.track_window = (upper_left_x, upper_left_y, w, h)\n",
    "            self.end_selection = True\n",
    "\n",
    "def get_matched_image(img_scene, img_obj, kp_obj, des_object, sift):\n",
    "    \"\"\"Identifica a posição de um objeto em uma outra imagem.\n",
    "\n",
    "    Args:\n",
    "        img_scene: Imagem global na qual o objeto será buscado\n",
    "        img_obj: Imagem do objeto a ser buscado\n",
    "        kp_obj: Pontos salientes do objeto previamente calculados\n",
    "        des_object: Descritores dos pontos salientes do objeto\n",
    "        sift: Instância do detector SIFT\n",
    "\n",
    "    Returns:\n",
    "        Imagem contendo o bounding box de `img_obj` na imagem `img_scene`\n",
    "    \"\"\"\n",
    "\n",
    "    # Detecta os pontos salientes e realiza o casamento\n",
    "    kp_scene, des_scene = sift.detectAndCompute(img_scene, None)\n",
    "    bf = cv2.BFMatcher(crossCheck=True)\n",
    "    matches = bf.knnMatch(des_object, des_scene, k=1)\n",
    "\n",
    "    # Mantém apenas os pontos que possuem uma correspondência na outra imagem\n",
    "    good = []\n",
    "    for m in matches:\n",
    "        if len(m)!=0:\n",
    "            good.append(m[0])\n",
    "\n",
    "    if len(good)<=10:\n",
    "        img_matches_ransac = cv2.drawMatches(img_obj, kp_obj, img_scene, kp_scene, good, None)\n",
    "    else:\n",
    "        obj_pts = np.zeros((len(good), 2), dtype=np.float32)\n",
    "        scene_pts = np.zeros((len(good), 2), dtype=np.float32)\n",
    "        for i, m in enumerate(good):\n",
    "            obj_pts[i] = kp_obj[m.queryIdx].pt\n",
    "            scene_pts[i] = kp_scene[m.trainIdx].pt\n",
    "\n",
    "        # Mapeia os pontos do objeto na imagem global\n",
    "        T, mask = cv2.findHomography(obj_pts, scene_pts, cv2.RANSAC, ransacReprojThreshold=3.0) \n",
    "        h, w = img_obj.shape\n",
    "        obj_bounds = np.float32(((0, 0), (0, h-1), (w-1, h-1), (w-1, 0))).reshape(-1,1,2)\n",
    "        obj_bounds_in_scene = cv2.perspectiveTransform(obj_bounds, T)\n",
    "\n",
    "        img_scene_obj = cv2.polylines(img_scene.copy(), [np.int32(obj_bounds_in_scene)], True, 255, 3, cv2.LINE_AA)\n",
    "        img_matches_ransac = img_scene_obj\n",
    "\n",
    "    return img_matches_ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Captura a imagem atual da câmera quando o usuário pressiona a tecla 'q'\n",
    "# A imagem capturada será usada para selecionar o objeto a ser rastreado\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Seleção do objeto pelo usuário\n",
    "rs = RegionSelector(frame)        \n",
    "upper_left_x, upper_left_y, w, h = rs.track_window\n",
    "\n",
    "img_obj = frame[upper_left_y:upper_left_y+h, upper_left_x:upper_left_x+w]\n",
    "img_obj_g = cv2.cvtColor(img_obj, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Pontos salientes do objeto, calculados apenas uma vez\n",
    "sift = cv2.SIFT_create(nfeatures=0, nOctaveLayers=3, contrastThreshold=0.02, \n",
    "                        edgeThreshold=10, sigma=1.6)\n",
    "kp_obj, des_obj = sift.detectAndCompute(img_obj_g, None)\n",
    "\n",
    "while(True):\n",
    "    # Captura imagem atual da câmera\n",
    "    ret, frame = cap.read()\n",
    "    frame_g = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Redimensiona imagem para melhor performance\n",
    "    frame_g_res = cv2.resize(frame_g, (640, 360))\n",
    "    img_matches_ransac = get_matched_image(\n",
    "        frame_g_res, \n",
    "        img_obj_g,\n",
    "        kp_obj, \n",
    "        des_obj, \n",
    "        sift\n",
    "        )  \n",
    "\n",
    "    # Mostra o resultado\n",
    "    cv2.imshow('frame', img_matches_ransac)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
